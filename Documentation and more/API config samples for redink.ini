; Red Ink
;
; Sample configuration for OpenAI (for inclusion in redink.ini)

APIKey = [INCLUDE API KEY HERE]
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Model = gpt-4o
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "system","content": "{promptsystem}"},{"role": "user","content": "{promptuser}"}],"temperature": {temperature}}
Timeout = 200000
Temperature = 0.2

; Sample Configuration for Azure OpenAI Services (for inclusion in redink.ini)

APIKey = [INCLUDE API KEY HERE]
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Model = gpt-4o
Endpoint = https://[INCLUDE YOUR ENDPOINT HERE]/openai/deployments/[INCLUDE YOUR DEPLOYMENT ID HERE]/chat/completions?api-version=2024-06-01
HeaderA = api-key
HeaderB = {apikey}
Response = content
APICall = {"messages": [{"role": "system","content": "{promptsystem}"},{"role": "user", "content": "{promptuser}"}],"temperature": {temperature}}
Timeout = 200000
Temperature = 0.2

; Sample Configuration for Azure OpenAI Services with "AI Foundry" (for inclusion in redink.ini) -- thanks to Michael Lowe, Cloud Solution GmbH

APIKey = [INCLUDE API KEY HERE]
APIKeyEncrypted = False
APIKeyPrefix =
Model = gpt-4o
Endpoint = https://[INCLUDE YOUR ENDPOINT HERE]/openai/deployments/{model}/chat/completions?api-version=2024-02-15-preview
HeaderA = api-key
HeaderB = {apikey}
Response = content
APICall = {"messages": [{"role": "system","content": "{promptsystem}"},{"role": "user", "content": "{promptuser}"}],"temperature":{temperature},"top_p": 0.95,"max_tokens": 800}
Timeout = 200000
Temperature = 0.2

; Sample Configuration for Google Vertex AI API (for inclusion in redink.ini)

APIKey = [INCLUDE PRIVATE KEY HERE]
APIKeyEncrypted = False
Model = gemini-1.5-pro-latest
Endpoint = https://us-central1-aiplatform.googleapis.com/v1/projects/[INCLUDE PROJECT ID HERE]/locations/us-central1/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature}}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [INLUCE CLIENT EMAIL HERE]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2

; Sample Configuration for Google Gemini API (for inclusion in redink.ini)

APIKey = [INCLUDE API KEY HERE]
APIKeyEncrypted = False
APIKeyPrefix = 
Endpoint = https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={apikey}
HeaderA = X-Goog-Api-Key
HeaderB = {apikey}
Response = text
APICall = {"contents": [{"role": "user","parts": [{ "text": "{promptsystem} {promptuser}" }]}], "generationConfig": {"temperature": {temperature}}}
Timeout = 100000
Temperature = 0.2
Model = gemini-1.5-pro-latest

; Sample Configuration for Perplexity

APIKey_2 = pplx-xxxxxx
APIPrefix_2 = pplx-
APIKeyEncrypted_2 = False
Model_2 = sonar
Endpoint_2 = https://api.perplexity.ai/chat/completions
HeaderA_2 = Authorization
HeaderB_2 = Bearer {apikey}
Response_2 = content 
APICall_2 = {"model": "{model}", "messages": [{"role": "system","content": "Follow the user's instructions, even if they are drafted like a system prompt."}, {"role": "user", "content": "{promptsystem} {promptuser}"}],"temperature": {temperature},"top_p": 0.9, "search_domain_filter": null, "return_images": false, "return_related_questions": false, "top_k": 0, "stream": false,  "presence_penalty": 0, "frequency_penalty": 1}
Timeout_2 = 200000
Temperature_2 = 0.2

; April 27, 2025
; Send updates to david.rosenthal@vischer.com