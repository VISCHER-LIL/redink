; Configuration for alternative models

[Perplexity Sonar Pro: Will also search the Internet (3.3 Min. Timeout, USA)]

APIKey = pplx-xxxxxx
APIKeyPrefix = pplx-
APIKeyEncrypted = False
Model = sonar-pro
Endpoint = https://api.perplexity.ai/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content 
APICall = {"model": "{model}", "messages": [{"role": "system","content": "Follow the user's instructions, even if they are drafted like a system prompt."}, {"role": "user", "content": "{promptsystem} {promptuser}"}],"temperature": {temperature},"top_p": 0.9, "search_domain_filter": null, "return_images": false, "return_related_questions": false, "top_k": 0, "stream": false,  "presence_penalty": 0, "frequency_penalty": 1}
Timeout = 200000
Temperature = 0.2

[Perplexity Sonar Reasoning Pro: Will reason and search the Internet (6.6 Min. Timeout, USA)]

APIKey = pplx-xxxxxx
APIKeyPrefix = pplx-
APIKeyEncrypted = False
Model = sonar-reasoning-pro
Endpoint = https://api.perplexity.ai/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content 
APICall = {"model": "{model}", "messages": [{"role": "system","content": "Follow the user's instructions, even if they are drafted like a system prompt."}, {"role": "user", "content": "{promptsystem} {promptuser}"}],"temperature": {temperature},"top_p": 0.9, "search_domain_filter": null, "return_images": false, "return_related_questions": false, "top_k": 0, "stream": false,  "presence_penalty": 0, "frequency_penalty": 1}
Timeout = 400000
Temperature = 0.2

[Perplexity Sonar Deep Research: Will reason and search the Internet ($$, 30 Min. Timeout, USA)]

APIKey = pplx-xxxxxx
APIKeyPrefix = pplx-
APIKeyEncrypted = False
Model = sonar-deep-research
Endpoint = https://api.perplexity.ai/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content 
APICall = {"model": "{model}", "messages": [{"role": "system","content": "Follow the user's instructions, even if they are drafted like a system prompt."}, {"role": "user", "content": "{promptsystem} {promptuser}"}],"temperature": {temperature},"top_p": 0.9, "search_domain_filter": null, "return_images": false, "return_related_questions": false, "top_k": 0, "stream": false,  "presence_penalty": 0, "frequency_penalty": 1}
Timeout = 1800000
Temperature = 0.2


[Google Gemini 2.0 Flash Experimental: Test usage only, image generation (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.0-flash-exp
Endpoint = https://us-central1-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/us-central1/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"responseModalities":["Text", "Image"]}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 320000
Temperature = 0.2

[Google Gemini 2.5 Pro - minimum reasoning (NL)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.5-pro
Endpoint = https://europe-west4-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/europe-west4/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature},  "thinking_config": {"thinking_budget": 128}}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2

[Google Gemini 2.5 Pro - auto reasoning (NL)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.5-pro
Endpoint = https://europe-west4-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/europe-west4/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature}}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2

[Google Gemini 2.5 Pro - auto reasoning, Internet search (NL)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.5-pro
Endpoint = https://europe-west4-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/europe-west4/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature}}, "tools": [{"google_search": {}}]}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 400000
Temperature = 0.2

[Google Gemini 2.5 Pro - maximum reasoning (NL)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.5-pro
Endpoint = https://europe-west4-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/europe-west4/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature},  "thinking_config": {"thinking_budget": 32768}}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 400000
Temperature = 0.2


[Google Gemini 2.5 Flash - no reasoning (NL)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.5-flash
Endpoint = https://europe-west4-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/europe-west4/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature},  "thinking_config": {"thinking_budget": 0}}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2

[Google Gemini 2.5 Flash - auto reasoning (NL)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.5-flash
Endpoint = https://europe-west4-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/europe-west4/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature}}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2


[Google Gemini 2.5 Flash - minimal reasoning, Internet search (NL)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.5-flash
Endpoint = https://europe-west4-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/europe-west4/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature},  "thinking_config": {"thinking_budget": 256}}, "tools": [{"google_search": {}}]}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 100000
Temperature = 0.2


[Google Gemini 2.5 Flash - maximum reasoning, Internet search (NL)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.5-flash
Endpoint = https://europe-west4-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/europe-west4/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature},  "thinking_config": {"thinking_budget": 24576}}, "tools": [{"google_search": {}}]}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 300000
Temperature = 0.2



[Google Gemini 3 Pro Preview - reasoning 'low' (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False

Model = gemini-3-pro-preview
Endpoint = https://aiplatform.googleapis.com/v1/projects/[your-project-ID]/locations/global/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature},  "thinking_config": {"thinking_level": "low"}}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [your-account-email]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2

[Google Gemini 3 Pro Preview - reasoning 'high' (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False

Model = gemini-3-pro-preview
Endpoint = https://aiplatform.googleapis.com/v1/projects/[your-project-ID]/locations/global/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature},  "thinking_config": {"thinking_level": "high"}}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [your-account-email]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 500000
Temperature = 0.2


[Google Gemini 3 Pro Preview - reasoning 'low', Internet search (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False

Model = gemini-3-pro-preview
Endpoint = https://aiplatform.googleapis.com/v1/projects/[your-project-ID]/locations/global/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature},  "thinking_config": {"thinking_level": "low"}}, "tools": [{"google_search": {}}]}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [your-account-email]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 500000
Temperature = 0.2


[Google Gemini 3 Pro Image Preview (use 'Pure:') - standard (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-3-pro-image-preview
Endpoint = https://aiplatform.googleapis.com/v1/projects/[your-project-ID]/locations/global/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature}}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [your-account-email]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 400000
Temperature = 0.2


[Google Gemini 3 Pro Image Preview (use 'Pure:') - with parameters (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False

Model = gemini-3-pro-image-preview
Endpoint = https://aiplatform.googleapis.com/v1/projects/[your-project-ID]/locations/global/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"temperature": {temperature}, "imageConfig": {"aspectRatio": "{parameter1=Aspect Ration; String; 1:1; 1:1, 3:2, 2:3, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9, 21:9}"}}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [your-account-email]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 500000
Temperature = 0.2


[Google Gemini 3 Pro Image Preview (use 'Pure:') - with parameters, Internet search (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False

Model = gemini-3-pro-image-preview
Endpoint = https://aiplatform.googleapis.com/v1/projects/[your-project-ID]/locations/global/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "tools": [{"google_search": {}}], "generationConfig": {"temperature": {temperature}, "imageConfig": {"aspectRatio": "{parameter1=Aspect Ration; String; 1:1; 1:1, 3:2, 2:3, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9, 21:9}"}}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [your-account-email]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 500000
Temperature = 0.2



[Google Imagen 3 Generate 002 (use 'Pure:') - image generation (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = imagen-3.0-generate-002
Endpoint = https://aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/global/publishers/google/models/{model}:predict
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"instances": [{"prompt": "{promptsystem} {promptuser}"}],"parameters": {"sampleCount": 1, "enhancePrompt": true}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2

[Google Imagen 4 Ultra Generate Preview (use 'Pure:') - image generation (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = imagen-4.0-ultra-generate-preview-06-06
Endpoint = https://aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/global/publishers/google/models/{model}:predict
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"instances": [{"prompt": "{promptsystem} {promptuser}"}],"parameters": {"sampleCount": 1, "enhancePrompt": true}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2

[OpenAI GPT-5.1: Latest model, medium reasoning, supports image input (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "system","content": "{promptsystem}"},{"role": "user","content": [{ "type": "text", "text": "{promptuser}"}{objectcall}]}],"temperature": {temperature}}
APICall_Object = , {"type": "image_url", "image_url": {"url": "data:{mimetype};base64,{encodeddata}"}}
Timeout = 500000
Temperature = 1.0
Model = gpt-5.1

[OpenAI GPT-5: Current model, minimal reasoning (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/responses
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"model": "{model}",  "input": "{promptsystem} {promptuser}", "reasoning": {"effort": "minimal"}}
Timeout = 350000
Temperature = 1.0
Model = gpt-5

[OpenAI GPT-5: Current model, medium reasoning, supports image input (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "system","content": "{promptsystem}"},{"role": "user","content": [{ "type": "text", "text": "{promptuser}"}{objectcall}]}],"temperature": {temperature}}
APICall_Object = , {"type": "image_url", "image_url": {"url": "data:{mimetype};base64,{encodeddata}"}}
Timeout = 500000
Temperature = 1.0
Model = gpt-5

[OpenAI GPT-5: Current model, maximum reasoning (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/responses
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"model": "{model}",  "input": "{promptsystem} {promptuser}", "reasoning": {"effort": "high"}}
Timeout = 200000
Temperature = 1.0
Model = gpt-5


[OpenAI GPT-5-mini: Current, fast model for most requests, supports image input (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "system","content": "{promptsystem}"},{"role": "user","content": [{ "type": "text", "text": "{promptuser}"}{objectcall}]}],"temperature": {temperature}}
APICall_Object = , {"type": "image_url", "image_url": {"url": "data:{mimetype};base64,{encodeddata}"}}
Timeout = 200000
Temperature = 1.0
Model = gpt-5-mini


[OpenAI GPT-4.1: Older model for most requests (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "system","content": "{promptsystem}"},{"role": "user","content": [{ "type": "text", "text": "{promptuser}"}]}],"temperature": {temperature}}
Timeout = 200000
Temperature = 0.2
Model = gpt-4.1

[OpenAI GPT-4o: Older model for most requests (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "system","content": "{promptsystem}"},{"role": "user","content": [{ "type": "text", "text": "{promptuser}"}]}],"temperature": {temperature}}
Timeout = 200000
Temperature = 0.2
Model = gpt-4o

[OpenAI GPT-4o-search-preview: Older model plus Internet search (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "web_search_options": {}, "messages": [{"role": "system","content": "{promptsystem}"},{"role": "user","content": [{ "type": "text", "text": "{promptuser}"}{objectcall}]}]}
APICall_Object = , {"type": "image_url", "image_url": {"url": "data:{mimetype};base64,{encodeddata}"}}
Timeout = 200000
Temperature = 0.2
Model = gpt-4o-search-preview


[OpenAI o3-mini: Older, fast reasoning model (5 Min. Timeout, USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "user","content": "{promptsystem} {promptuser}"}],"temperature": {temperature}}
Timeout = 300000
Temperature = 1.0
Model = o3-mini

[OpenAI o3: Older, more advanced reasoning model (5 Min. Timeout, USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "user","content": "{promptsystem} {promptuser}"}],"temperature": {temperature}}	
Timeout = 300000
Temperature = 1.0
Model = o3

[OpenAI o1: High-end reasoning model ($, 10 Min. Timeout, USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "user","content": "{promptsystem} {promptuser}"}],"temperature": {temperature}}
Timeout = 600000
Temperature = 1.0
Model = o1

[OpenAI o4 Mini Deep Research: Normal Deep Research (10 Min. Timeout, USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/responses
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"model": "{model}", "input": "{promptsystem} {promptuser}", "tools": [{ "type": "web_search_preview" },{ "type": "code_interpreter", "container": { "type": "auto" } }]}
Timeout = 600000
Temperature = 1.0
Model = o4-mini-deep-research

[OpenAI o3 Deep Research: Higher-End Deep Research ($$, 20 Min. Timeout, USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/responses
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"model": "{model}", "input": "{promptsystem} {promptuser}", "tools": [{ "type": "web_search_preview" },{ "type": "code_interpreter", "container": { "type": "auto" } }]}
Timeout = 1200000
Temperature = 1.0
Model = o3-deep-research

[OpenAI GPT Image-1: Image Creation (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/images/generations
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"model": "{model}", "prompt": "{promptsystem} {promptuser}"}
Timeout = 200000
Temperature = 1.0
Model = gpt-image-1

[OpenAI GPT Image-1: Image Editing (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/images/edits
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = not used
APICall_Object = multipart:model:{model};prompt:{promptsystem} {promptuser};filefield:image[]
Timeout = 500000
Temperature = 1.0
Model = gpt-image-1

[Infomaniak: Qwen3, no reasoning (CH)]

; Qwen3-235B-A22B-Instruct-2507

APIKey = xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = 
Endpoint = https://api.infomaniak.com/1/ai/[infomaniak_product_id]/openai/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "user","content": "{promptsystem} {promptuser}"}],"temperature": {temperature}}
Timeout = 200000
Temperature = 0.2
Model = qwen3

[Infomaniak: DeepSeek-R1, reasoning (CH)]

; DeepSeek-R1-distilled-qwen-32B

APIKey = xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = 
Endpoint = https://api.infomaniak.com/1/ai/[infomaniak_product_id]/openai/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content (nothink)
APICall = {"model": "{model}",  "messages": [{"role": "user","content": "{promptsystem} {promptuser}"}],"temperature": {temperature}}
Timeout = 300000
Temperature = 0.2
Model = reasoning

[Infomaniak: Flux, image generation (CH, use 'Pure:' prefix)]

; Use "Pure:" prefix in Freestyle

APIKey = xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = 
Endpoint = https://api.infomaniak.com/1/ai/[infomaniak_product_id]/openai/images/generations
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = revised_prompt
APICall = {"model": "{model}",  "prompt": "{promptsystem} {promptuser}", "quality": "standard"}
;APICall = {"model": "{model}",  "prompt": "{promptsystem} {promptuser}", "quality": "hd", "size": "1792x1024"}
Timeout = 400000
Temperature = 1
Model = flux

[MTF: Llama3, no reasoning (CH)]

APIKey = xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = 
Endpoint = https://api.ai.mtf.cloud/chatbot/ask
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "user","content": "{promptsystem} {promptuser}"}],"temperature": {temperature}}
Timeout = 200000
Temperature = 0.2
Model = meta-llama-ai


[SafeSwissCloud: gpt-oss-120b (CH)]

APIKey = xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = 
Endpoint = https://llm01.safeswisscloud.ch/engines/{model}/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "user","content": "{promptsystem} {promptuser}"}],"temperature": {temperature}}
Timeout = 200000
Temperature = 0.2
Model = gpt-oss-120b


[SafeSwissCloud: Variable Model (CH)]

APIKey = xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = 
Endpoint = https://llm01.safeswisscloud.ch/engines/{model}/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "user","content": "{promptsystem} {promptuser}"}],"temperature": {temperature}}
Timeout = 200000
Temperature = 0.2
Model = {parameter1=Modell; String; gpt-oss-120b; apertus-8b, apertus-70b, deepseekr1-70b, deepseekr1-670b, mistral-v03-7b, qwen3-8b, qwq-32b, qwq25-vl-72b, llama33-70b, llama4-maverick, llama4-scout-17b, granite-33-8b, granite-emb-278m, bge-m3, kimi-k2, gemma-12b-it, granite-vision-2b, gpt-oss-120b}



[Ollama: qwen3:30b]

; Generic setup sample for LLM instances using Ollama, eg. running on a Portainer setup
; Contributed by layer-8-law

APIKey = xxxxxx
Endpoint = http://[DOMAIN-OR-IP-ADDRESS]:[PORT]/api/chat
; Endpoint: must point to your Ollama instance either using domain or IP and specific port (default:11434)
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model":"{model}","messages":[   {"role":"system","content":"{promptsystem}"},   {"role":"user","content":"{promptuser}"{objectcall}} ], "stream": false, "think": false, "options":{"temperature": {temperature}}}
; APICall: if you remove "think": false or set it to true, Ollama will respond including the thinking process. This will clutter up your documents or dialogs but may include useful hints for debugging.
Timeout = 100000
Temperature = 0.2
Model = qwen3:30b
; Model: set to your desired model as labeled in OpenWebUI or Ollama, eg. qwen3:30b or ministral-3:14b etc.
OAuth2 = False
OAuth2ClientMail = 
OAuth2Scopes = 
OAuth2Endpoint = 
OAuth2ATExpiry = 0

[OpenWebUI: qwen3:30b]

; Generic setup for LLM instances using OpenWebUI, eg. running on a Portainer setup]
; Contributed by layer-8-law

APIKey = xxxxxx
Endpoint = http://[DOMAIN-OR-IP-ADDRESS]:[PORT]/api/chat/completions
; Endpoint: must point to your OpenWebUI instance either using domain or IP and specific port (default: 3000)
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model":"{model}","messages": [{"role":"system","content":"{promptsystem}"}, {"role":"user","content":"{promptuser}"{objectcall}}],"stream":false,"temperature":{temperature}}
; APICall: No "think": false or similar needed. OpenWebUI will respond only with content in this configuration.
Timeout = 100000
Temperature = 0.2
Model = qwen3:30b
; Model: set to your desired model as labeled in OpenWebUI or Ollama, eg. qwen3:30b or ministral-3:14b etc.
OAuth2 = False
OAuth2ClientMail = 
OAuth2Scopes = 
OAuth2Endpoint = 
OAuth2ATExpiry = 0