; Configuration for alternative models

[Perplexity Sonar Pro: Will also search the Internet (3.3 Min. Timeout, USA)]

APIKey = pplx-xxxxxx
APIKeyPrefix = pplx-
APIKeyEncrypted = False
Model = sonar-pro
Endpoint = https://api.perplexity.ai/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content 
APICall = {"model": "{model}", "messages": [{"role": "system","content": "Follow the user's instructions, even if they are drafted like a system prompt."}, {"role": "user", "content": "{promptsystem} {promptuser}"}],"temperature": {temperature},"top_p": 0.9, "search_domain_filter": null, "return_images": false, "return_related_questions": false, "top_k": 0, "stream": false,  "presence_penalty": 0, "frequency_penalty": 1}
Timeout = 200000
Temperature = 0.2

[Perplexity Sonar Reasoning Pro: Will reason and search the Internet (6.6 Min. Timeout, USA)]

APIKey = pplx-xxxxxx
APIKeyPrefix = pplx-
APIKeyEncrypted = False
Model = sonar-reasoning-pro
Endpoint = https://api.perplexity.ai/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content 
APICall = {"model": "{model}", "messages": [{"role": "system","content": "Follow the user's instructions, even if they are drafted like a system prompt."}, {"role": "user", "content": "{promptsystem} {promptuser}"}],"temperature": {temperature},"top_p": 0.9, "search_domain_filter": null, "return_images": false, "return_related_questions": false, "top_k": 0, "stream": false,  "presence_penalty": 0, "frequency_penalty": 1}
Timeout = 400000
Temperature = 0.2

[Perplexity Sonar Deep Research: Will reason and search the Internet ($$, 30 Min. Timeout, USA)]

APIKey = pplx-xxxxxx
APIKeyPrefix = pplx-
APIKeyEncrypted = False
Model = sonar-deep-research
Endpoint = https://api.perplexity.ai/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content 
APICall = {"model": "{model}", "messages": [{"role": "system","content": "Follow the user's instructions, even if they are drafted like a system prompt."}, {"role": "user", "content": "{promptsystem} {promptuser}"}],"temperature": {temperature},"top_p": 0.9, "search_domain_filter": null, "return_images": false, "return_related_questions": false, "top_k": 0, "stream": false,  "presence_penalty": 0, "frequency_penalty": 1}
Timeout = 1800000
Temperature = 0.2


[Google Gemini 2.0 Flash Experimental: Test usage only, image generation (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.0-flash-exp
Endpoint = https://us-central1-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/us-central1/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}{objectcall}]}], "generationConfig": {"responseModalities":["Text", "Image"]}}
APICall_Object = , {"inlineData": {"mimeType": "{mimetype}","data": "{encodeddata}"}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 320000
Temperature = 0.2

[Google Gemini 2.5 Pro (NL)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.5-pro
Endpoint = https://europe-west4-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/us-central1/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}]}], "generationConfig": {"temperature": {temperature}}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2

[Google Gemini 2.5 Flash (NL)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = gemini-2.5-flash
Endpoint = https://europe-west4-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/us-central1/publishers/google/models/{model}:generateContent
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"contents": [{"role": "user", "parts":[{"text": "{promptsystem} {promptuser}"}]}], "generationConfig": {"temperature": {temperature}}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2


[Google Imagen 3 Generate 002: Image generation (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = imagen-3.0-generate-002
Endpoint = https://us-central1-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/us-central1/publishers/google/models/{model}:predict
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"instances": [{"prompt": "{promptsystem} {promptuser}"}],"parameters": {"sampleCount": 1, "enhancePrompt": true}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2

[Google Imagen 4 Ultra Generate Preview: Image generation (USA)]

APIKey = xxxxxx
APIKeyEncrypted = False
Model = imagen-4.0-ultra-generate-preview-06-06
Endpoint = https://us-central1-aiplatform.googleapis.com/v1/projects/[yourprojectid]/locations/us-central1/publishers/google/models/{model}:predict
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"instances": [{"prompt": "{promptsystem} {promptuser}"}],"parameters": {"sampleCount": 1, "enhancePrompt": true}}
OAuth2 = True
OAuth2ClientMail = [youraccountmail]
OAuth2Scopes = https://www.googleapis.com/auth/cloud-platform
OAuth2Endpoint = https://oauth2.googleapis.com/token
OAuth2ATExpiry = 3600
Timeout = 200000
Temperature = 0.2

[OpenAI GPT-4.1: Latest model for most requests (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "system","content": "{promptsystem}"},{"role": "user","content": [{ "type": "text", "text": "{promptuser}"}]}],"temperature": {temperature}}
Timeout = 200000
Temperature = 0.2
Model = gpt-4.1

[OpenAI GPT-4o: Normal model for most requests (USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "system","content": "{promptsystem}"},{"role": "user","content": [{ "type": "text", "text": "{promptuser}"}]}],"temperature": {temperature}}
Timeout = 200000
Temperature = 0.2
Model = gpt-4o

[OpenAI o3-mini: Fast reasoning model (5 Min. Timeout, USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "user","content": "{promptsystem} {promptuser}"}],"temperature": {temperature}}
Timeout = 300000
Temperature = 1.0
Model = o3-mini

[OpenAI o3: More advanced reasoning model (5 Min. Timeout, USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "user","content": "{promptsystem} {promptuser}"}],"temperature": {temperature}}	
Timeout = 300000
Temperature = 1.0
Model = o3

[OpenAI o1: High-end reasoning model ($, 10 Min. Timeout, USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/chat/completions
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = content
APICall = {"model": "{model}",  "messages": [{"role": "user","content": "{promptsystem} {promptuser}"}],"temperature": {temperature}}
Timeout = 600000
Temperature = 1.0
Model = o1

[OpenAI o4 Mini Deep Research: Normal Deep Research (10 Min. Timeout, USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/responses
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"model": "{model}", "input": "{promptsystem} {promptuser}", "tools": [{ "type": "web_search_preview" },{ "type": "code_interpreter", "container": { "type": "auto" } }]}
Timeout = 600000
Temperature = 1.0
Model = o4-mini-deep-research

[OpenAI o3 Deep Research: Higher-End Deep Research ($$, 20 Min. Timeout, USA)]

APIKey = sk-proj-xxxxxx
APIKeyEncrypted = False
APIKeyPrefix = sk-proj-
Endpoint = https://api.openai.com/v1/responses
HeaderA = Authorization
HeaderB = Bearer {apikey}
Response = text
APICall = {"model": "{model}", "input": "{promptsystem} {promptuser}", "tools": [{ "type": "web_search_preview" },{ "type": "code_interpreter", "container": { "type": "auto" } }]}
Timeout = 1200000
Temperature = 1.0
Model = o3-deep-research
